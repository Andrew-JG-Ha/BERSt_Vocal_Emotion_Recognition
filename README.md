BERSt Vocal Emotion Recognition - Cmpt 419 final project
===============
Authors of this project: Andrew Ha, Lachlan Ellis, Justin Baek

**File Structure**
â””â”€â”€ ğŸ“BERSt_Vocal_Emotion_Recognition
    â””â”€â”€ .gitignore
    â””â”€â”€ ğŸ“models
        â””â”€â”€ CNN.ipynb
        â””â”€â”€ combined_model.ipynb
        â””â”€â”€ DataProcessing.ipynb
        â””â”€â”€ LSTM_and_Merger.ipynb
        â””â”€â”€ RNN.ipynb
    â””â”€â”€ README.md
    â””â”€â”€ test_set.csv
    â””â”€â”€ test_set_annotated.csv
    â””â”€â”€ test_set_annotated2.csv
    â””â”€â”€ training_set.csv
    â””â”€â”€ valid_data.csv

**Project Evaluation**
The initial goal of this project was to apply various models onto the BERSt dataset in an attempt to determine the best model to use for speech emotion recognition with the added noise due to distance. We were successful in creating all of the models we had wanted to and we were able to obtain results from the models. The only change made to the initial proposal was the shifting of tasks, Andrew was to do the combination of 2 models together, this task was given to Justin and Andrew's task was updated to also working on the report.
